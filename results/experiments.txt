Some basic results

basinsGivenProbabilityT1 Storkey 36 2 0.1
10.5

basinsGivenProbabilityT1 Storkey 36 2 0.2
11

basinsGivenProbabilityT1 Storkey 36 2 0.3
11

basinsGivenProbabilityT1 Storkey 36 2 0.4
12

basinsGivenProbabilityT1 Storkey 36 2 0.5
12.5

basinsGivenProbabilityT1 Storkey 36 2 0.6
12.5

basinsGivenProbabilityT1 Storkey 36 2 0.7
12.5



basinsGivenStdT2 Hebbian 50 2 25 5
10.0


basinsGivenStdT2 Storkey 50 2 25 5
18.0


basinsGivenStdT2 Storkey 50 5 25 5
4.8

basinsGivenStdT2 Hebbian 50 5 25 5
4.4


basinsGivenStdT2 Hebbian 50 4 25 5
8.275
basinsGivenStdT2 Storkey 50 4 25 5
6.975
basinsGivenStdT2 Hebbian 50 6 25 10
4.45
basinsGivenStdT2 Storkey 50 6 25 10
5.616666666666666

basinsGivenStdT2 Hebbian 50 6 25 5
6.783333333333333
basinsGivenStdT2 Storkey 50 6 25 5
4.633333333333334
basinsGivenStdT2 Hebbian 50 4 25 10
7.325
basinsGivenStdT2 Storkey 50 4 25 10
9.2


dist/build/smallexp/small





"T1 experiment with 1 cluster"
  putStrLn $ show $ evalRand (repeatExperiment experimentUsingT1 Hebbian 1 50 8) (mkStdGen 1)
2.5686274509803924

"T1 experiment with 1 cluster"
  putStrLn $ show $ evalRand (repeatExperiment experimentUsingT1 Storkey 1 50 8) (mkStdGen 1)

7.522058823529412


T2 experiment with 1 cluster with no average but lists
(0.0,49.0) (2.0,14.4) (12.5,3.3)



mcr10@pixel04 ~/gp/imperialhopfield (git)-[parallel] % dist/build/clusterexp/cluster
T2 in IO() to be able to use parallel map with 50 neurons cluster of size 5
[(24.0,0.0),(9.2,2.0),(9.2,4.0),(4.8,6.0)]
[(24.0,0.0),(9.4,2.0),(9.2,4.0),(9.0,6.0)]
[(24.0,0.0),(4.6,2.0),(4.4,4.0),(4.4,6.0)]
[(24.0,0.0),(4.6,2.0),(9.2,4.0),(4.6,6.0)]
[(24.0,0.0),(4.6,2.0),(4.4,4.0),(4.4,6.0)]
[(24.0,0.0),(13.8,2.0),(4.6,4.0),(4.6,6.0)]
[(24.0,0.0),(4.6,2.0),(4.6,4.0),(4.0,6.0)]
[(24.0,0.0),(4.6,2.0),(4.6,4.0),(5.8,6.0)]
[(24.0,0.0),(9.2,2.0),(4.4,4.0),(4.4,6.0)]
[(24.0,0.0),(9.6,2.0),(4.6,4.0),(4.6,6.0)]
[(24.0,0.0),(4.6,2.0),(4.6,4.0),(4.2,6.0)]

T2 in IO() to be able to use parallel map with 50 neurons cluster of size 5
[(13.8,1.0),(9.2,3.0),(4.4,5.0),(5.2,7.0)]
[(9.2,1.0),(4.6,3.0),(9.2,5.0),(8.8,7.0)]
[(9.4,1.0),(4.6,3.0),(3.4,5.0),(5.8,7.0)]
[(14.4,1.0),(9.2,3.0),(9.2,5.0),(4.4,7.0)]
[(9.4,1.0),(4.6,3.0),(4.4,5.0),(3.6,7.0)]
[(9.2,1.0),(4.6,3.0),(4.6,5.0),(4.6,7.0)]
[(9.2,1.0),(4.6,3.0),(4.4,5.0),(3.4,7.0)]
[(14.4,1.0),(4.6,3.0),(1.4,5.0),(4.8,7.0)]
[(13.8,1.0),(4.6,3.0),(4.6,5.0),(0.8,7.0)]
[(9.2,1.0),(4.6,3.0),(4.6,5.0),(4.4,7.0)]
[(4.6,1.0),(4.6,3.0),(4.4,5.0),(2.8,7.0)]


T2 in IO() to be able to use parallel map std dev 0.0 2.0 and 12.5
[49.0,9.6,9.2]


T2 in IO() to be able to use parallel map with 50 neurons cluster of size 6
[29.0,14.0,9.333333333333334,14.0,9.333333333333334]
dist/build/clusterexp/clusterexp  503.22s user 5.29s system 99% cpu 8:30.08 total


T2 60 5
[(29.0,0.0),(17.0,1.0),(5.6,2.0),(5.6,3.0),(5.6,4.0),(5.4,5.0),(5.6,6.0),(5.6,7.0),(5.4,8.0)]
[(29.0,0.0),(11.2,1.0),(11.2,2.0),(5.6,3.0),(11.2,4.0),(11.2,5.0),(11.0,6.0),(11.0,7.0),(5.4,8.0)]
[(29.0,0.0),(17.4,1.0),(17.4,2.0),(5.8,3.0),(5.6,4.0),(5.6,5.0),(5.6,6.0),(5.6,7.0),(5.4,8.0)]
[(29.0,0.0),(17.2,1.0),(11.6,2.0),(11.4,3.0),(11.2,4.0),(5.6,5.0),(5.6,6.0),(11.0,7.0),(5.6,8.0)]
[(29.0,0.0),(16.8,1.0),(5.8,2.0),(5.6,3.0),(11.2,4.0),(5.6,5.0),(5.6,6.0),(5.6,7.0),(5.4,8.0)]
[(29.0,0.0),(17.4,1.0),(5.6,2.0),(5.6,3.0),(5.6,4.0),(5.6,5.0),(5.4,6.0),(5.6,7.0),(5.4,8.0)]

dist/build/clusterexp/clusterexp  3928.05s user 43.49s system 99% cpu 1:06:23.75 total



T1 experiment with 1 cluster with no average but lists 100 and 10
[(0.0,49.0),(0.1,0.0),(0.2,0.0),(0.30000000000000004,0.0),(0.4000000000000001,20.4),(0.5000000000000001,18.2)]
^L[(0.0,49.0),(0.1,0.0),(0.2,0.0),(0.30000000000000004,0.1),(0.4000000000000001,19.1),(0.5000000000000001,23.2)]
[(0.0,49.0),(0.1,0.0),(0.2,0.0),(0.30000000000000004,0.1),(0.4000000000000001,17.4),(0.5000000000000001,20.8)]
[(0.0,49.0),(0.1,0.0),(0.2,0.0),(0.30000000000000004,0.3),(0.4000000000000001,17.5),(0.5000000000000001,21.9)]
